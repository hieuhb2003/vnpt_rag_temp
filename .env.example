# =============================================================================
# RAG System Environment Configuration
# =============================================================================
# Copy this file to .env and fill in the values

# -----------------------------------------------------------------------------
# API Configuration
# -----------------------------------------------------------------------------
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
DEBUG=false

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
# Provider: "anthropic" or "openai"
LLM_PROVIDER=anthropic

# Anthropic API Key (required if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx

# OpenAI API Key (required if LLM_PROVIDER=openai or for embeddings)
OPENAI_API_KEY=sk-xxxxx

# Model selection
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
# OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
LLM_MODEL=claude-3-5-sonnet-20241022

# Custom Base URL for OpenAI-compatible APIs (optional)
# Leave empty to use default provider endpoints
# Examples:
# - OpenRouter: https://openrouter.ai/api/v1
# - Azure OpenAI: https://your-resource.openai.azure.com/openai/deployments/your-deployment
# - Local LLM: http://localhost:8000/v1
LLM_BASE_URL=

# -----------------------------------------------------------------------------
# Embedding Configuration
# -----------------------------------------------------------------------------
# Provider: "openai" or "local"
# - openai: Uses OpenAI API (requires API key, faster, higher quality)
# - local: Uses sentence-transformers (free, runs on CPU/GPU, good for multilingual)
EMBEDDING_PROVIDER=local

# Model selection
# OpenAI models:
#   - text-embedding-3-small (1536 dims, fast, cost-effective)
#   - text-embedding-3-large (3072 dims, best quality)
#   - text-embedding-ada-002 (1536 dims, legacy)
#
# Local models (sentence-transformers):
#   - paraphrase-multilingual-MiniLM-L12-v2 (384 dims, multilingual, fast)
#   - paraphrase-multilingual-mpnet-base-v2 (768 dims, multilingual, better quality)
#   - sentence-transformers/all-MiniLM-L6-v2 (384 dims, English only)
#   - BAAI/bge-base-en-v1.5 (768 dims, English, good for QA)
#   - BAAI/bge-small-en-v1.5 (384 dims, English, compact)
#   - intfloat/multilingual-e5-large (1024 dims, multilingual, high quality)
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# Embedding dimensions (must match model)
# OpenAI:
#   - text-embedding-3-small: 1536 (can reduce to 512 or 256)
#   - text-embedding-3-large: 3072 (can reduce)
#   - text-embedding-ada-002: 1536
# Local (common dimensions):
#   - 384: MiniLM models (fast, compact)
#   - 768: MPNet models (good quality)
#   - 1024: Large multilingual models
#   - 1536: Same as OpenAI for compatibility
EMBEDDING_DIMENSIONS=384

# -----------------------------------------------------------------------------
# Qdrant Vector Database
# -----------------------------------------------------------------------------
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_API_KEY=

# -----------------------------------------------------------------------------
# PostgreSQL Database
# -----------------------------------------------------------------------------
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=ragdb
POSTGRES_USER=raguser
POSTGRES_PASSWORD=your_secure_password_here

# -----------------------------------------------------------------------------
# Redis Cache
# -----------------------------------------------------------------------------
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password_here

# -----------------------------------------------------------------------------
# MinIO Object Storage
# -----------------------------------------------------------------------------
MINIO_HOST=minio
MINIO_PORT=9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=your_minio_secret_here
MINIO_BUCKET=documents

# -----------------------------------------------------------------------------
# Indexing Configuration
# -----------------------------------------------------------------------------
# Chunk size in tokens (recommended: 400-512)
CHUNK_SIZE=512

# Overlap between chunks in tokens (recommended: 10-20% of chunk size)
CHUNK_OVERLAP=50

# Maximum depth for document tree structure
MAX_TREE_DEPTH=5

# -----------------------------------------------------------------------------
# Retrieval Configuration
# -----------------------------------------------------------------------------
# Hybrid search weight: 0=keyword only, 1=vector only, 0.7=balanced
HYBRID_ALPHA=0.7

# Number of results at each level
TOP_K_DOCUMENTS=5
TOP_K_SECTIONS=10
TOP_K_CHUNKS=20

# -----------------------------------------------------------------------------
# Caching Configuration
# -----------------------------------------------------------------------------
# TTL in seconds for different cache types
CACHE_EMBEDDING_TTL=3600
CACHE_RETRIEVAL_TTL=1800
CACHE_SEMANTIC_TTL=3600

# Semantic similarity threshold for cache hits (0.0-1.0)
SEMANTIC_CACHE_THRESHOLD=0.85

# -----------------------------------------------------------------------------
# Verification Configuration
# -----------------------------------------------------------------------------
# Groundedness check threshold (0.0-1.0)
GROUNDEDNESS_THRESHOLD=0.85

# Enable Tier 2 LLM verification when Tier 1 fails
ENABLE_TIER2_VERIFICATION=true

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST_SIZE=10

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
LOG_LEVEL=INFO
LOG_FORMAT=json
